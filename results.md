# Results


Caveat: none of the results are statistically significant, as I only run a single random seed.
Also, there are probably plenty of bugs and shortcuts in the code.

### 1 - Result

First we train on the first 45 timesteps and test on the next 10 timesteps of a single trajectory

![image](data/animations/default.pdf)

### 2 - Training on more data

![image](data/animations/default.pdf)

### 3 - Including noise

Noise increases train loss but reduces test loss.
hypothesis: noise helps when there is more data.

### 4 - Training and testing on different trajectories

We train on 500 timesteps randomly selected out of 3 training trajectories (3*599 steps) and test on 90 timesteps of a 4th trajectory. This takes about 4h on a RTX 3060.

(plot was generated by wandb)

## Reproduce runs

I used the following runs to generate the data:
- default `python run_gnn.py`
- default-dataset_stanford `python run_gnn.py +dataset=stanford`
- default-noise_paper `python run_gnn.py +noise=paper`
- default-datasize_small-noise_paper `python run_gnn.py +noise=paper +datasize=small`
- default-datasize_small-testset_different `python run_gnn.py +testset=different +datasize=small`
- default-datasize_small-testset_different-noise_paper `python run_gnn.py +noise=paper +testset=different +datasize=small`

## Project goal

There existed a (prior PyTorch project by three Stanford students)[https://medium.com/stanford-cs224w/learning-mesh-based-flow-simulations-on-graph-networks-44983679cf2d]
which I build on. Thank you!
But the project (a) did not include code to generate their data (b) did not add noise during training (c) could not train and test on different trajectories (d) was partially broken (e) lacked infrastructure to run experiments

I:
- Added code to convert the original data (.tfrecord) into a general format (.hdf5)
- Rebuild the Colab project code into a working codebase
- Added noise during training, as in the original paper
- Added bells and whistles to run experiments (train and test on different trajectories, wandb logging, hydra configs, resume checkpoints)

I also looked into predicting the sizing field for a couple of hours.
One would need to implement the sizing field prediction and the sizing-based remesher.
